{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########使用的库###########\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########使用到的函数栏###########\n",
    "\n",
    "def load_train_data():\n",
    "    train_data=pd.read_csv(\"./train.csv\")\n",
    "    return train_data\n",
    "\n",
    "def load_test_data():\n",
    "    test_data=pd.read_csv(\"./test.csv\")\n",
    "    return test_data\n",
    "\n",
    "def category2num1(series):\n",
    "    mapping1={\"Ex\":0,\"Gd\":1,\"TA\":2,\"Fa\":3,\"Po\":4}\n",
    "    return series.map(mapping1)\n",
    "\n",
    "def category2num2(series):\n",
    "    mapping2={\"Ex\":0,\"Gd\":1,\"TA\":2,\"Fa\":3,\"Po\":4,\"None\":5}\n",
    "    return series.map(mapping2)\n",
    "\n",
    "def category2num3(series):\n",
    "    mapping3={\"Gd\":0,\"Av\":1,\"Mn\":2,\"No\":3,\"None\":4}\n",
    "    return series.map(mapping3)\n",
    "\n",
    "def category2num4(series):\n",
    "    mapping4={\"GLQ\":0,\"ALQ\":1,\"BLQ\":2,\"Rec\":3,\"LwQ\":4,\"Unf\":5,\"None\":6}\n",
    "    return series.map(mapping4)\n",
    "\n",
    "def category2num5(series):\n",
    "    mapping5={\"Fin\":0,\"RFn\":1,\"Unf\":2,\"None\":3}\n",
    "    return series.map(mapping5)\n",
    "\n",
    "def standard(series):\n",
    "    series=(series-series.mean())/series.std()\n",
    "    return series\n",
    "\n",
    "def valuation(prediction,labels):\n",
    "    res=np.sqrt(mean_squared_error(prediction,labels))\n",
    "    return res\n",
    "\n",
    "###########使用到的函数栏###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########获取训练数据和预测数据和训练目标###########\n",
    "train_data=load_train_data()\n",
    "test_data=load_test_data()\n",
    "\n",
    "#获取目标值和特征,**这个等去除完异常值再进行**\n",
    "#train_labels=np.log(train_data['SalePrice'])\n",
    "#train_data=train_data.drop(['SalePrice',\"Id\"],axis=1)\n",
    "#test_data=test_data.drop([\"Id\"],axis=1)\n",
    "\n",
    "#test_labels=np.log(test_data[\"SalePrice\"])\n",
    "#test_data=test_data.drop([\"SalePrice\"],axis=1)\n",
    "\n",
    "###########获取训练数据和预测数据和训练目标###########\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460\n",
      "LotFrontage      259\n",
      "Alley           1369\n",
      "MasVnrType       872\n",
      "MasVnrArea         8\n",
      "BsmtQual          37\n",
      "BsmtCond          37\n",
      "BsmtExposure      38\n",
      "BsmtFinType1      37\n",
      "BsmtFinType2      38\n",
      "Electrical         1\n",
      "FireplaceQu      690\n",
      "GarageType        81\n",
      "GarageYrBlt       81\n",
      "GarageFinish      81\n",
      "GarageQual        81\n",
      "GarageCond        81\n",
      "PoolQC          1453\n",
      "Fence           1179\n",
      "MiscFeature     1406\n",
      "dtype: int64\n",
      "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
      "       'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope',\n",
      "       'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle',\n",
      "       'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle',\n",
      "       'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrArea', 'ExterQual',\n",
      "       'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure',\n",
      "       'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF',\n",
      "       'TotalBsmtSF', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical',\n",
      "       '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath',\n",
      "       'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr',\n",
      "       'KitchenQual', 'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'GarageType',\n",
      "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
      "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
      "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',\n",
      "       'MoSold', 'YrSold', 'SaleType', 'SaleCondition', 'SalePrice'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "###########根据缺失值的情况，决定删除掉哪些列###########\n",
    "\n",
    "print(len(train_data))\n",
    "\n",
    "#要是有异常值要先replace转化为na\n",
    "#为了能够看清楚哪些列的空值所以增加一个筛选出有空值的列再看哪个控制大一些\n",
    "train_data_full_sum=train_data.isna().sum()\n",
    "print(train_data_full_sum[train_data_full_sum>0])\n",
    "test_data_full_sum=test_data.isna().sum()\n",
    "test_data_full_sum[test_data_full_sum>0]\n",
    "\n",
    "#删除掉空值占50%以上的列，因为这些列信息少，说明应该没用\n",
    "train_data=train_data.drop([\"Alley\",\"MasVnrType\",\"FireplaceQu\",\"PoolQC\",\"Fence\",\"MiscFeature\"],axis=1)\n",
    "test_data=test_data.drop([\"Alley\",\"MasVnrType\",\"FireplaceQu\",\"PoolQC\",\"Fence\",\"MiscFeature\"],axis=1)\n",
    "print(train_data.columns)\n",
    "\n",
    "train_data.drop_duplicates(inplace=True)\n",
    "test_data.drop_duplicates(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n"
     ]
    }
   ],
   "source": [
    "###########对数值列有异常值的列进行删除###########\n",
    "\n",
    "#选择只为数值的数据类型，因为类别变量是自己指定的，不会有偏差很大的异常值出现\n",
    "#numeric_cols=train_data.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "#自己根据列的实际意义来决定什么列要进行异常值的剔除\n",
    "#只参照一些不包含零值的，即每个房子正常都会有的来判断什么房子比较特殊便不予考虑\n",
    "selected_columns=[\"LotFrontage\",\"LotArea\",\"TotalBsmtSF\",\"GrLivArea\",\"GarageArea\"]\n",
    "\n",
    "for col in selected_columns:\n",
    "    Q1=train_data[col].quantile(0.25)\n",
    "    Q3=train_data[col].quantile(0.75)\n",
    "    IQR=Q3-Q1\n",
    "    #观察数据后，发现数据较为离散，因为数值型中有不少0以及一些大数据并存，所以我们主要限制太大的数据，而放宽对小数据的限制，因为一些用户可能没有这方面的需求\n",
    "    #所以默认为0\n",
    "    low_bound=Q1-20*IQR\n",
    "    high_bound=Q3+20*IQR\n",
    "    train_data=train_data[((train_data[col]>=low_bound) & (train_data[col]<=high_bound))]\n",
    "\n",
    "print(len(train_data))\n",
    "\n",
    "train_labels=np.log(train_data['SalePrice'])\n",
    "train_data=train_data.drop(['SalePrice',\"Id\"],axis=1)\n",
    "test_data=test_data.drop([\"Id\"],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [MSSubClass, MSZoning, LotFrontage, LotArea, Street, LotShape, LandContour, Utilities, LotConfig, LandSlope, Neighborhood, Condition1, Condition2, BldgType, HouseStyle, OverallQual, OverallCond, YearBuilt, YearRemodAdd, RoofStyle, RoofMatl, Exterior1st, Exterior2nd, MasVnrArea, ExterQual, ExterCond, Foundation, BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinSF1, BsmtFinType2, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF, Heating, HeatingQC, CentralAir, Electrical, 1stFlrSF, 2ndFlrSF, LowQualFinSF, GrLivArea, BsmtFullBath, BsmtHalfBath, FullBath, HalfBath, BedroomAbvGr, KitchenAbvGr, KitchenQual, TotRmsAbvGrd, Functional, Fireplaces, GarageType, GarageYrBlt, GarageFinish, GarageCars, GarageArea, GarageQual, GarageCond, PavedDrive, WoodDeckSF, OpenPorchSF, EnclosedPorch, 3SsnPorch, ScreenPorch, PoolArea, MiscVal, MoSold, YrSold, SaleType, SaleCondition]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 73 columns]\n"
     ]
    }
   ],
   "source": [
    "###########缺失值的处理###########\n",
    "\n",
    "#第一种找到相关联的特征的进行分组用groupby，然后再取中位数\n",
    "train_data[\"LotFrontage\"]=train_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x : x.fillna(x.median()))\n",
    "test_data[\"LotFrontage\"]=test_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x : x.fillna(x.median()))\n",
    "\n",
    "#第二种直接填充众数，因为缺失值较少，填充众数比填充中位数鲁棒性要强\n",
    "train_data[\"Electrical\"]=train_data[\"Electrical\"].fillna(train_data[\"Electrical\"].mode()[0])\n",
    "\n",
    "#第三种填充none和0\n",
    "# 地板类型和面积，这两者是一致的\n",
    "#train_data['MasVnrType'] = train_data['MasVnrType'].fillna('None')\n",
    "train_data['MasVnrArea'] = train_data['MasVnrArea'].fillna(0)\n",
    "#test_data['MasVnrType'] = test_data['MasVnrType'].fillna('None')\n",
    "test_data['MasVnrArea'] = test_data['MasVnrArea'].fillna(0)\n",
    "# NA用None填充，表示没有地下室\n",
    "for col in ['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']:\n",
    "    train_data[col] = train_data[col].fillna('None')\n",
    "    test_data[col] = test_data[col].fillna('None')\n",
    "    #print(test_data[col])\n",
    "for col in ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath']:\n",
    "    test_data[col] = test_data[col].fillna(0)\n",
    "# NA用None填充，表示没有车库\n",
    "for col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:\n",
    "    train_data[col] = train_data[col].fillna('None')\n",
    "    test_data[col] = test_data[col].fillna('None')\n",
    "train_data['GarageYrBlt'] = train_data['GarageYrBlt'].fillna(0)\n",
    "test_data['GarageYrBlt'] = test_data['GarageYrBlt'].fillna(0)\n",
    "# GarageCars、GarageArea\n",
    "for col in ['GarageCars','GarageArea']:\n",
    "    test_data[col] = test_data[col].fillna(0)\n",
    "# MSZoning、utilities、KitchenQual、Functional、SaleType\n",
    "for col in ['MSZoning','Utilities','KitchenQual','Functional','SaleType']:\n",
    "    test_data[col] = test_data[col].fillna(test_data[col].mode()[0])\n",
    "# Exterior1st、Exterior2nd\n",
    "test_data['Exterior1st'] = test_data['Exterior1st'].fillna(test_data['Exterior1st'].mode()[0])\n",
    "test_data['Exterior2nd'] = test_data['Exterior2nd'].fillna(test_data['Exterior1st'].mode()[0])\n",
    "\n",
    "\n",
    "#train_isnull2 = train_data.isnull().sum()\n",
    "# print(type(train_isnull))    Series\n",
    "#print(train_isnull2[train_isnull2 > 0])\n",
    "#test_isnull2 = test_data.isnull().sum()\n",
    "# print(type(train_isnull))    Series\n",
    "#print(test_isnull2[test_isnull2 > 0])\n",
    "print(test_data[test_data[\"BsmtFinType1\"]==\"NA\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########数据编码###########\n",
    "\n",
    "train_data_number=train_data.shape[0]\n",
    "#test_data_number=test_data.shape[0]\n",
    "\n",
    "all_data=pd.concat((train_data,test_data)).reset_index(drop=True)\n",
    "#print(len(train_data))\n",
    "#print(train_data[\"BsmtFinType1\"])\n",
    "\n",
    "all_data['MSSubClass'] = all_data['MSSubClass'].astype(str)\n",
    "all_data['ExterQual'] = category2num1(all_data['ExterQual'])\n",
    "all_data['ExterCond'] = category2num1(all_data['ExterCond'])\n",
    "all_data['BsmtQual'] = category2num2(all_data['BsmtQual'])\n",
    "all_data['BsmtCond'] = category2num2(all_data['BsmtCond'])\n",
    "all_data['BsmtExposure'] = category2num3(all_data['BsmtExposure'])\n",
    "all_data['BsmtFinType1'] = category2num4(all_data['BsmtFinType1'])\n",
    "all_data['BsmtFinType2'] = category2num4(all_data['BsmtFinType2'])\n",
    "all_data['HeatingQC'] = category2num1(all_data['HeatingQC'])\n",
    "all_data['KitchenQual'] = category2num2(all_data['KitchenQual'])\n",
    "all_data['GarageFinish'] = category2num5(all_data['GarageFinish'])\n",
    "all_data['GarageQual'] = category2num2(all_data['GarageQual'])\n",
    "all_data['GarageCond'] = category2num2(all_data['GarageCond'])\n",
    "\n",
    "#print(all_data[\"MasVnrType\"])\n",
    "\n",
    "#采用labelEncoder的，因为类别之间有优劣之分\n",
    "for col in ['OverallQual','OverallCond','YearBuilt','YearRemodAdd', 'ExterQual','ExterCond', 'BsmtQual', 'BsmtCond',\n",
    "            'BsmtExposure','BsmtFinType1', 'BsmtFinType2','HeatingQC','CentralAir','BsmtFullBath','BsmtHalfBath',\n",
    "            'FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr','KitchenQual','TotRmsAbvGrd' ,'Fireplaces',\n",
    "            'GarageYrBlt','GarageFinish','GarageCars','MiscVal','MoSold','YrSold']:\n",
    "            le=LabelEncoder()\n",
    "            #print(all_data[col])\n",
    "            le.fit(all_data[col])\n",
    "            #print(all_data[col])\n",
    "            is_null=all_data[col].isna().sum()\n",
    "            if is_null>0:\n",
    "                print(col)\n",
    "            all_data[col]=le.transform(all_data[col])\n",
    "\n",
    "for col in ['MSSubClass', 'MSZoning','Street','LotShape','LandContour','Utilities','LotConfig','LandSlope',\n",
    "            'Neighborhood','Condition1','Condition2','BldgType','HouseStyle','RoofStyle','RoofMatl','Exterior1st',\n",
    "            'Exterior2nd','Foundation','Heating','Electrical','Functional','GarageType','PavedDrive',\n",
    "            'SaleType','SaleCondition']:\n",
    "    all_cols=pd.get_dummies(all_data[col],prefix=col)\n",
    "    all_data=pd.concat([all_data,all_cols],axis=1)\n",
    "    all_data=all_data.drop(col,axis=1)\n",
    "\n",
    "for col in ['LotFrontage','LotArea','MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','1stFlrSF',\n",
    "             '2ndFlrSF','LowQualFinSF','GrLivArea','GarageArea','WoodDeckSF','OpenPorchSF','EnclosedPorch','3SsnPorch',\n",
    "             'ScreenPorch','PoolArea']:\n",
    "     all_data[col] = standard(all_data[col])\n",
    "\n",
    "\n",
    "train_data=all_data[:train_data_number]\n",
    "test_data=all_data[train_data_number:]\n",
    "\n",
    "#对测试集编码\n",
    "# test_data['MSSubClass'] = test_data['MSSubClass'].astype(str)\n",
    "# test_data['ExterQual'] = category2num1(test_data['ExterQual'])\n",
    "# test_data['ExterCond'] = category2num1(test_data['ExterCond'])\n",
    "# test_data['BsmtQual'] = category2num2(test_data['BsmtQual'])\n",
    "# test_data['BsmtCond'] = category2num2(test_data['BsmtCond'])\n",
    "# test_data['BsmtExposure'] = category2num3(test_data['BsmtExposure'])\n",
    "# test_data['BsmtFinType1'] = category2num4(test_data['BsmtFinType1'])\n",
    "# test_data['BsmtFinType2'] = category2num4(test_data['BsmtFinType2'])\n",
    "# test_data['HeatingQC'] = category2num1(test_data['HeatingQC'])\n",
    "# test_data['KitchenQual'] = category2num2(test_data['KitchenQual'])\n",
    "# test_data['GarageFinish'] = category2num5(test_data['GarageFinish'])\n",
    "# test_data['GarageQual'] = category2num2(test_data['GarageQual'])\n",
    "# test_data['GarageCond'] = category2num2(test_data['GarageCond'])\n",
    "\n",
    "#print(test_data[\"KitchenQual\"])\n",
    "\n",
    "#采用labelEncoder的，因为类别之间有优劣之分\n",
    "# for col in ['OverallQual','OverallCond','YearBuilt','YearRemodAdd', 'ExterQual','ExterCond', 'BsmtQual', 'BsmtCond',\n",
    "#             'BsmtExposure','BsmtFinType1', 'BsmtFinType2','HeatingQC','CentralAir','BsmtFullBath','BsmtHalfBath',\n",
    "#             'FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr','KitchenQual','TotRmsAbvGrd' ,'Fireplaces',\n",
    "#             'GarageYrBlt','GarageFinish','GarageCars','MiscVal','MoSold','YrSold']:\n",
    "#             le=LabelEncoder()\n",
    "#             #print(test_data[col])\n",
    "#             le.fit(test_data[col])\n",
    "#             #print(test_data[col])\n",
    "#             is_null=test_data[col].isna().sum()\n",
    "#             if is_null>0:\n",
    "#                 print(col)\n",
    "#             test_data[col]=le.transform(test_data[col])\n",
    "\n",
    "# for col in ['MSSubClass', 'MSZoning','Street','LotShape','LandContour','Utilities','LotConfig','LandSlope',\n",
    "#             'Neighborhood','Condition1','Condition2','BldgType','HouseStyle','RoofStyle','RoofMatl','Exterior1st',\n",
    "#             'Exterior2nd','Foundation','Heating','Electrical','Functional','GarageType','PavedDrive',\n",
    "#             'SaleType','SaleCondition']:\n",
    "#     all_cols=pd.get_dummies(test_data[col],prefix=col)\n",
    "#     test_data=pd.concat([test_data,all_cols],axis=1)\n",
    "#     test_data=test_data.drop(col,axis=1)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgboost score 0.1314 0.0038\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001796 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1358\n",
      "[LightGBM] [Info] Number of data points in the train set: 960, number of used features: 181\n",
      "[LightGBM] [Info] Start training from score 12.014093\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003475 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1357\n",
      "[LightGBM] [Info] Number of data points in the train set: 960, number of used features: 181\n",
      "[LightGBM] [Info] Start training from score 12.014931\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001354 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1356\n",
      "[LightGBM] [Info] Number of data points in the train set: 960, number of used features: 181\n",
      "[LightGBM] [Info] Start training from score 12.018006\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001544 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1367\n",
      "[LightGBM] [Info] Number of data points in the train set: 960, number of used features: 184\n",
      "[LightGBM] [Info] Start training from score 12.014141\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001560 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1364\n",
      "[LightGBM] [Info] Number of data points in the train set: 960, number of used features: 181\n",
      "[LightGBM] [Info] Start training from score 12.014519\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "LightGBM score 0.1297 0.0017\n",
      "KRR score: 0.1607 (0.0288)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###########模型建立与交叉验证看效果调整参数###########\n",
    "\n",
    "n_folds=5\n",
    "def rmsle_cv(model):\n",
    "    kf=KFold(n_folds,shuffle=True,random_state=42)\n",
    "    nmse=cross_val_score(model,train_data.values,train_labels.values,cv=kf,scoring='neg_mean_squared_error')\n",
    "    return (nmse)\n",
    "\n",
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468,\n",
    "                             learning_rate=0.05, max_depth=3,\n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, \n",
    "                              nthread = -1)\n",
    "\n",
    "score_xgb=rmsle_cv(model_xgb)\n",
    "score_xgb=np.sqrt(-score_xgb)\n",
    "print(\"Xgboost score {:.4f} {:.4f}\".format(score_xgb.mean(),score_xgb.std()))\n",
    "\n",
    "model_lgb=lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n",
    "\n",
    "score_lgb=rmsle_cv(model_lgb)\n",
    "score_lgb=np.sqrt(-score_lgb)\n",
    "print(\"LightGBM score {:.4f} {:.4f}\".format(score_lgb.mean(),score_lgb.std()))\n",
    "\n",
    "KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "score_krr = rmsle_cv(KRR)\n",
    "score_krr=np.sqrt(-score_krr)\n",
    "print(\"KRR score: {:.4f} ({:.4f})\\n\".format(score_krr.mean(), score_krr.std()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0885412661021795\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1404\n",
      "[LightGBM] [Info] Number of data points in the train set: 1200, number of used features: 190\n",
      "[LightGBM] [Info] Start training from score 12.015138\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "0.07419266672868606\n",
      "0.08209340416009005\n"
     ]
    }
   ],
   "source": [
    "###########模型学习并在训练集上测试###########\n",
    "\n",
    "model_xgb.fit(train_data.values, train_labels)\n",
    "model_xgb_prec = model_xgb.predict(train_data.values)\n",
    "print(valuation(model_xgb_prec, train_labels))\n",
    "\n",
    "model_lgb.fit(train_data.values, train_labels)\n",
    "model_lgb_prec = model_lgb.predict(train_data.values)\n",
    "print(valuation(model_lgb_prec, train_labels))\n",
    "\n",
    "KRR.fit(train_data.values, train_labels)\n",
    "KRR_prec = KRR.predict(train_data.values)\n",
    "print(valuation(KRR_prec, train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "########### debug找出train_data和test_data哪些列不一样 ###########\n",
    "\n",
    "unique_train_data=set(train_data.columns)-set(test_data.columns)\n",
    "print(unique_train_data)\n",
    "unique_test_data=set(test_data.columns)-set(train_data.columns)\n",
    "print(unique_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    }
   ],
   "source": [
    "###########模型bagging###########\n",
    "\n",
    "model_xgb_res = model_xgb.predict(test_data.values)\n",
    "model_lgb_res = model_lgb.predict(test_data.values)\n",
    "KRR_res = KRR.predict(test_data.values)\n",
    "\n",
    "final_res = 0.3 * np.expm1(model_xgb_res) + 0.5 * np.expm1(model_lgb_res) + 0.2 * np.expm1(KRR_res)\n",
    "\n",
    "submission = pd.read_csv(\"sample_submission.csv\")\n",
    "submission['SalePrice'] = final_res\n",
    "submission.to_csv('submission_2.csv', index=None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textToSql",
   "language": "python",
   "name": "texttosql"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb58733487753431c450c0eaae16527e85b9a191c3389262b2f342e5c6e2bebe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
